{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "     ---------------------------------------- 7.9/7.9 MB 19.5 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.19.3-py3-none-any.whl (311 kB)\n",
      "     ------------------------------------- 311.2/311.2 KB 18.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python310\\lib\\site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python310\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python310\\lib\\site-packages (from transformers) (21.3)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.0-cp310-none-win_amd64.whl (277 kB)\n",
      "     -------------------------------------- 277.4/277.4 KB 8.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\python310\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.0-cp310-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 20.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python310\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python310\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "     ------------------------------------- 166.4/166.4 KB 10.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python310\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Installing collected packages: safetensors, fsspec, filelock, huggingface-hub, tokenizers, transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python310\\\\Scripts\\\\huggingface-cli.exe' -> 'C:\\\\Python310\\\\Scripts\\\\huggingface-cli.exe.deleteme'\n",
      "\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "     ---------------------------------------- 84.1/84.1 KB ? eta 0:00:00\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "     ---------------------------------------- 115.3/115.3 KB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python310\\lib\\site-packages (from evaluate) (1.24.2)\n",
      "Requirement already satisfied: packaging in c:\\python310\\lib\\site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\python310\\lib\\site-packages (from evaluate) (2023.10.0)\n",
      "Collecting datasets>=2.0.0\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "     ------------------------------------- 521.2/521.2 KB 16.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\python310\\lib\\site-packages (from evaluate) (1.5.1)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "     -------------------------------------- 134.8/134.8 KB 7.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\python310\\lib\\site-packages (from evaluate) (0.19.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\python310\\lib\\site-packages (from evaluate) (2.28.1)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\python310\\lib\\site-packages (from evaluate) (4.64.1)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-14.0.1-cp310-cp310-win_amd64.whl (24.6 MB)\n",
      "     --------------------------------------- 24.6/24.6 MB 19.3 MB/s eta 0:00:00\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.6-cp310-cp310-win_amd64.whl (325 kB)\n",
      "     ------------------------------------- 325.2/325.2 KB 19.7 MB/s eta 0:00:00\n",
      "Collecting pyarrow-hotfix\n",
      "  Downloading pyarrow_hotfix-0.5-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python310\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\python310\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python310\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->evaluate) (2022.9.14)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas->evaluate) (2022.6)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.2/61.2 KB ? eta 0:00:00\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n",
      "     ---------------------------------------- 61.0/61.0 KB 3.4 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-win_amd64.whl (44 kB)\n",
      "     ---------------------------------------- 44.4/44.4 KB 2.3 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, frozenlist, dill, attrs, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets, evaluate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'C:\\\\Python310\\\\Scripts\\\\get_gprof'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in c:\\python310\\lib\\site-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python310\\\\Scripts\\\\rouge.exe' -> 'C:\\\\Python310\\\\Scripts\\\\rouge.exe.deleteme'\n",
      "\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install transformers\n",
    "!pip install evaluate\n",
    "!pip install rouge\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nT5ForConditionalGeneration requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nivsi\\Desktop\\Classes at Brown\\CSCI2390\\QASystem\\mockup.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nivsi/Desktop/Classes%20at%20Brown/CSCI2390/QASystem/mockup.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m T5ForConditionalGeneration, T5Tokenizer\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nivsi/Desktop/Classes%20at%20Brown/CSCI2390/QASystem/mockup.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load pre-trained T5 model and tokenizer\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nivsi/Desktop/Classes%20at%20Brown/CSCI2390/QASystem/mockup.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m T5ForConditionalGeneration\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mt5-base\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nivsi/Desktop/Classes%20at%20Brown/CSCI2390/QASystem/mockup.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m T5Tokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mt5-base\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nivsi/Desktop/Classes%20at%20Brown/CSCI2390/QASystem/mockup.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Prepare input\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:1259\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_from_config\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1259\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[1;32mc:\\python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:1247\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1245\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[0;32m   1246\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nT5ForConditionalGeneration requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load pre-trained T5 model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "# Prepare input\n",
    "question = \"What is the capital of France?\"\n",
    "text_corpus = \"Paris is the capital of France.\"\n",
    "\n",
    "input_text = f\"question: {question} context: {text_corpus}\"\n",
    "\n",
    "# Tokenize and generate output\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output_ids = model.generate(input_ids)\n",
    "\n",
    "# Decode and print the answer\n",
    "answer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea:\n",
    " - Is this all in plaintext or is there some structure here?\n",
    " - Could we have multiple connectors? So the worst is plaintext, but if you can augment it with K9DB or RuleKeeper or something, it gets better?\n",
    "\n",
    "\n",
    "Question Gen\n",
    "- https://www.asd5.org/cms/lib4/WA01001311/Centricity/Domain/145/Costas.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)\n",
    "def ask_gpt(systemprompt, userprompt):\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": systemprompt},\n",
    "        {\"role\": \"user\", \"content\": userprompt}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message\n",
    "\n",
    "# Use this for now -- Gradescope policy, for instance, is FAR TOO LONG for GPT-3 completions. Need to think\n",
    "# of a way to split it up.\n",
    "def get_hardcoded_policy(url):\n",
    "    return '''Gradescope collects the following types of data and shares them with the corresponding entities:\n",
    "\n",
    "- Personal information: This may include names, email addresses, and other identifying details provided by users. It is shared with Gradescope's internal team, employees, and authorized service providers who need access to the information to perform their duties and improve the service. For example, the internal team may use personal information to verify user identities, provide customer support, and communicate important updates. Authorized service providers may include hosting providers, data storage providers, and analytics platforms who assist Gradescope in delivering and improving the service.\n",
    "- Usage data: This includes information about how users interact with the platform, such as the courses they enroll in, assignments they submit, and grades they receive. It is shared with Gradescope's internal team, employees, and authorized service providers who analyze the data to enhance the platform's features and functionality. This analysis helps Gradescope understand user preferences, identify areas for improvement, and make data-driven decisions to provide a better user experience. The internal team may also use usage data to monitor system performance, troubleshoot issues, and ensure the proper functioning of the platform.\n",
    "\n",
    "Gradescope takes appropriate measures to safeguard the collected data and respects user privacy in accordance with its privacy policy. These measures include implementing technical and organizational security measures to protect against unauthorized access, maintaining strict data confidentiality obligations for employees and service providers, and regularly monitoring and updating security practices to align with industry standards. It is important for users to review and understand the privacy policy to be aware of their rights and choices regarding their data.\n",
    "Gradescope does not sell or share personal information with third parties for marketing purposes. The collected data is used solely for the purposes stated in the privacy policy and to provide and improve the Gradescope service. Users can trust that their data is handled with care and in compliance with applicable laws and regulations.'''\n",
    "\n",
    "def get_policy_from_web(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text_with_html = soup.get_text()\n",
    "        text_without_html = html2text.html2text(text_with_html)\n",
    "        return text_without_html\n",
    "    else:\n",
    "        print(\"Failed to retrieve the webpage. Status code:\", response.status_code)\n",
    "\n",
    "\n",
    "# VERY BASIC, from https://www.geeksforgeeks.org/python-text-summarizer/\n",
    "def summarizer(text):\n",
    "    \n",
    "    # Tokenizing the text \n",
    "    stopWords = set(stopwords.words(\"english\")) \n",
    "    words = word_tokenize(text) \n",
    "    \n",
    "    # Creating a frequency table to keep the score of each word \n",
    "    \n",
    "    freqTable = dict() \n",
    "    for word in words: \n",
    "        word = word.lower() \n",
    "        if word in stopWords: \n",
    "            continue\n",
    "        if word in freqTable: \n",
    "            freqTable[word] += 1\n",
    "        else: \n",
    "            freqTable[word] = 1\n",
    "    \n",
    "    # Creating a dictionary to keep the score of each sentence \n",
    "    sentences = sent_tokenize(text) \n",
    "    sentenceValue = dict() \n",
    "    \n",
    "    for sentence in sentences: \n",
    "        for word, freq in freqTable.items(): \n",
    "            if word in sentence.lower(): \n",
    "                if sentence in sentenceValue: \n",
    "                    sentenceValue[sentence] += freq \n",
    "                else: \n",
    "                    sentenceValue[sentence] = freq \n",
    "    \n",
    "    sumValues = 0\n",
    "    for sentence in sentenceValue: \n",
    "        sumValues += sentenceValue[sentence] \n",
    "    \n",
    "    # Average value of a sentence from the original text \n",
    "    \n",
    "    average = int(sumValues / len(sentenceValue)) \n",
    "    \n",
    "    # Storing sentences into our summary. \n",
    "    summary = '' \n",
    "    for sentence in sentences: \n",
    "        if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)): \n",
    "            summary += \" \" + sentence \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costas Levels of Questioning\n",
    "\n",
    "https://www.asd5.org/cms/lib4/WA01001311/Centricity/Domain/145/Costas.pdf\n",
    "\n",
    "- LEVEL\t1: Remember Define, Show Understanding\n",
    "- LEVEL 2: Use Understanding, Examine, Create\n",
    "- LEVEL 3: Decide, Show Understanding, Supportive Evidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_costas_level_prompt(level):\n",
    "    if level == 1:\n",
    "        return \"\"\n",
    "    elif level == 2:\n",
    "        return \"\"\n",
    "    elif level == 3:\n",
    "        return \"\"\n",
    "    return \"\"\n",
    "\n",
    "def gen_question(context, level):\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow 1\n",
    "- Ask Question (Gen? Mockup? C.R.O.W.D.? Costas?)\n",
    "- Student Answers\n",
    "- Extract student answer, compare with privacy policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will abstract out to various connectors\n",
    "def get_system_prompt(policy_url):\n",
    "\n",
    "    plaintext_policy = get_policy_from_web(policy_url)\n",
    "\n",
    "    def rough_num_words(s):\n",
    "        return s.count(\" \") + 1\n",
    "    \n",
    "    c = 0\n",
    "    ## HAck bc of OpenAI Limits\n",
    "    while rough_num_words(plaintext_policy) > 3000 or c > 2:\n",
    "        print(\"SUMMARIZE!\")\n",
    "        c += 1\n",
    "        plaintext_policy = summarizer(plaintext_policy)\n",
    "\n",
    "\n",
    "    PLAINTEXT_SYSTEM_PROMPT = ''' You are a tutor helping determine whether users correctly understand the privacy policy below:\n",
    "        [PRIVACY POLICY]\n",
    "        {p}\n",
    "\n",
    "        For this policy, the student was asked a [QUESTION] and responded with an [ANSWER]. \n",
    "        Determine whether [ANSWER] answers [QUESTION], whether it was correct or incorrect.\n",
    "        {{\n",
    "            'Relevant' : [True if [ANSWER] answers [QUESTION], False otherwise],\n",
    "            'Correct' : [True if the answer is correct, False if incorrect],\n",
    "            'Explanation' : [A 2 sentence explanation of why the answer was correct or incorrect],\n",
    "            'Confidence' : [Your confidence in this decision on a scale of 0 to 1, with 0 being not confident and 1 being completely certain.]\n",
    "        }}\n",
    "\n",
    "    '''.format(p = plaintext_policy)\n",
    "    return PLAINTEXT_SYSTEM_PROMPT\n",
    "\n",
    "\n",
    "def get_user_prompt(question, answer):\n",
    "    return ''' \n",
    "\n",
    "        The student was asked the following question:\n",
    "        \n",
    "        [QUESTION] {q}\n",
    "\n",
    "        and gave the following answer:\n",
    "        [ANSWER] {a}\n",
    "    '''.format(q = question, a = answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_qa(q, a, pp):\n",
    "    system_prompt = get_system_prompt(policy_url=pp)\n",
    "    user_prompt = get_user_prompt(question = q, answer = a)\n",
    "    return ask_gpt(systemprompt=system_prompt, userprompt= user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARIZE!\n",
      "SUMMARIZE!\n",
      "ChatCompletionMessage(content=\"{\\n    'Relevant': True,\\n    'Correct': False,\\n    'Explanation': 'The answer is incorrect. The privacy policy does not specifically mention sharing personal information with course instructors.',\\n    'Confidence': 0.9\\n}\", role='assistant', function_call=None)\n"
     ]
    }
   ],
   "source": [
    "# Lets test it out\n",
    "\n",
    "policy = 'https://www.gradescope.com/privacy'\n",
    "question = 'With whom does Gradescope share your personal information?'\n",
    "answer = \"Gradescope only shares my personal information with course instructors\"\n",
    "\n",
    "print(check_qa(q = question, a = answer, pp = policy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow 2:\n",
    "- Student can ask questions about the Privacy Explorer\n",
    "- Explorer uses GPT to answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will abstract out to various connectors\n",
    "def flow_2_system_prompt(policy_url):\n",
    "\n",
    "\n",
    "    plaintext_policy = get_policy_from_web(policy_url)\n",
    "\n",
    "    def rough_num_words(s):\n",
    "        return s.count(\" \") + 1\n",
    "    \n",
    "    c = 0\n",
    "    ## Hack bc of OpenAI Limits\n",
    "    while rough_num_words(plaintext_policy) > 3000 or c > 2:\n",
    "        print(\"SUMMARIZE!\")\n",
    "        c += 1\n",
    "        plaintext_policy = summarizer(plaintext_policy)\n",
    "\n",
    "\n",
    "    PLAINTEXT_SYSTEM_PROMPT = ''' You are a tutor helping answer user questions about the privacy policy below:\n",
    "        [PRIVACY POLICY]\n",
    "        {p}\n",
    "\n",
    "\n",
    "    '''.format(p = plaintext_policy)\n",
    "    return PLAINTEXT_SYSTEM_PROMPT\n",
    "\n",
    "\n",
    "def flow_2_user_prompt(question):\n",
    "    return ''' \n",
    "        For this [PRIVACY POLICY], the student asked the following [QUESTION] and responded with an [ANSWER]. \n",
    "        \n",
    "        [QUESTION] {q}\n",
    "\n",
    "        Answer this question using only information from [PRIVACY POLICY]:\n",
    "        {{\n",
    "            'Answer' : [A short answer to the question],\n",
    "            'Confidence' : [Your confidence in this decision on a scale of 0 to 1, with 0 being not confident and 1 being completely certain.]\n",
    "        }}\n",
    "    '''.format(q = question, a = answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARIZE!\n",
      "SUMMARIZE!\n",
      "ChatCompletionMessage(content=\"{\\n            'Answer': 'Gradescope shares personal information with third-party service providers, such as language translation service providers, who have contractual agreements to handle and secure the data with the same level of protection as Turnitin.',\\n            'Confidence': 0.9\\n        }\", role='assistant', function_call=None)\n"
     ]
    }
   ],
   "source": [
    "def gen_a(q, pp):\n",
    "    system_prompt = flow_2_system_prompt(policy_url=pp)\n",
    "    user_prompt = flow_2_user_prompt(question = q)\n",
    "    return ask_gpt(systemprompt=system_prompt, userprompt= user_prompt)\n",
    "\n",
    "print(gen_a(q = question,  pp = policy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
